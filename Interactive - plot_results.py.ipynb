{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362eb59-7ddf-4b0e-9189-24fbf64e3e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "new(): data must be a sequence (got NoneType)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# # Iterate over each node and its data\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# for nodes_data in microservices_in_nodes:\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m#     microservices_per_node = []\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m#     for node_set in microservices_per_node:\u001b[39;00m\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m#         print(len(node_set))\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[43mplot_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mplot_results\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_results\u001b[39m():\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# np.random.seed(0)\u001b[39;00m\n\u001b[32m     10\u001b[39m     start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     results = \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     elapsed_time = time.time() - start_time\n\u001b[32m     13\u001b[39m     num_tests = \u001b[38;5;28mlen\u001b[39m(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/test_model.py:104\u001b[39m, in \u001b[36mtest_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    101\u001b[39m     num_active_agents += \u001b[32m1\u001b[39m\n\u001b[32m    103\u001b[39m     \u001b[38;5;66;03m# action_mask = env.get_action_mask(agent_id)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     action = \u001b[43mppo_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m     agent_actions.append(action)\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/PPO.py:184\u001b[39m, in \u001b[36mPPO_MARL.select_action\u001b[39m\u001b[34m(self, obs_state, agent_id, action_mask)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mselect_action\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs_state, agent_id=\u001b[32m0\u001b[39m, action_mask=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m         action_mask = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_mask\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m    185\u001b[39m         \u001b[38;5;66;03m# print(\"action_mask\", action_mask)\u001b[39;00m\n\u001b[32m    186\u001b[39m         actions, action_logprobs, state_val, dependencies_repr, graph_repr, requests_left = \u001b[38;5;28mself\u001b[39m.policy_old.act(obs_state, action_mask)\n",
      "\u001b[31mTypeError\u001b[39m: new(): data must be a sequence (got NoneType)"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361cb07-efb9-48fd-997b-5da4294344ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "new(): data must be a sequence (got NoneType)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# # Iterate over each node and its data\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# for nodes_data in microservices_in_nodes:\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m#     microservices_per_node = []\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m#     for node_set in microservices_per_node:\u001b[39;00m\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m#         print(len(node_set))\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[43mplot_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mplot_results\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_results\u001b[39m():\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# np.random.seed(0)\u001b[39;00m\n\u001b[32m     10\u001b[39m     start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     results = \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     elapsed_time = time.time() - start_time\n\u001b[32m     13\u001b[39m     num_tests = \u001b[38;5;28mlen\u001b[39m(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/test_model.py:104\u001b[39m, in \u001b[36mtest_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    101\u001b[39m     num_active_agents += \u001b[32m1\u001b[39m\n\u001b[32m    103\u001b[39m     \u001b[38;5;66;03m# action_mask = env.get_action_mask(agent_id)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     action = \u001b[43mppo_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m     agent_actions.append(action)\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/PPO.py:184\u001b[39m, in \u001b[36mPPO_MARL.select_action\u001b[39m\u001b[34m(self, obs_state, agent_id, action_mask)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mselect_action\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs_state, agent_id=\u001b[32m0\u001b[39m, action_mask=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m         action_mask = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_mask\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m    185\u001b[39m         \u001b[38;5;66;03m# print(\"action_mask\", action_mask)\u001b[39;00m\n\u001b[32m    186\u001b[39m         actions, action_logprobs, state_val, dependencies_repr, graph_repr, requests_left = \u001b[38;5;28mself\u001b[39m.policy_old.act(obs_state, action_mask)\n",
      "\u001b[31mTypeError\u001b[39m: new(): data must be a sequence (got NoneType)"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58529d74-4afe-4b9b-8b57-0e5eed109770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -427.28\n",
      "Episode: 2 \t\t Reward: -354.25\n",
      "Episode: 3 \t\t Reward: -603.1\n",
      "Episode: 4 \t\t Reward: -426.63\n",
      "Episode: 5 \t\t Reward: -410.71\n",
      "Episode: 6 \t\t Reward: -543.98\n",
      "Episode: 7 \t\t Reward: -367.27\n",
      "Episode: 8 \t\t Reward: -294.66\n",
      "Episode: 9 \t\t Reward: -356.96\n",
      "Episode: 10 \t\t Reward: -133.24\n",
      "Episode: 11 \t\t Reward: -283.02\n",
      "Episode: 12 \t\t Reward: -348.38\n",
      "Episode: 13 \t\t Reward: -292.4\n",
      "Episode: 14 \t\t Reward: -370.67\n",
      "Episode: 15 \t\t Reward: -293.54\n",
      "Episode: 16 \t\t Reward: -265.8\n",
      "Episode: 17 \t\t Reward: -233.98\n",
      "Episode: 18 \t\t Reward: -345.49\n",
      "Episode: 19 \t\t Reward: -373.26\n",
      "Episode: 20 \t\t Reward: -238.85\n",
      "============================================================================================\n",
      "average test reward : -348.17\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  93\n",
      "Average Power Consumption per Microservice:  23.26350947357191\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 3.124245345592499 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf98e5f-c82b-47cf-8746-8d24394fca6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "Inference for Episode 0. Total reward:  -319.8614507100189\n",
      "Inference for Episode 1. Total reward:  -324.6492244437167\n",
      "Inference for Episode 2. Total reward:  -281.5456265574607\n",
      "Inference for Episode 3. Total reward:  -487.31999947116515\n",
      "Inference for Episode 4. Total reward:  -476.7873205907815\n",
      "Inference for Episode 5. Total reward:  -370.3598897014829\n",
      "Inference for Episode 6. Total reward:  -295.3702618856724\n",
      "Inference for Episode 7. Total reward:  -322.2038032654781\n",
      "Inference for Episode 8. Total reward:  -218.84696535582538\n",
      "Inference for Episode 9. Total reward:  -241.0122193164874\n",
      "Inference for Episode 10. Total reward:  -321.6582575457038\n",
      "Inference for Episode 11. Total reward:  -460.959999863817\n",
      "Inference for Episode 12. Total reward:  -440.1113452933298\n",
      "Inference for Episode 13. Total reward:  -231.36211709735286\n",
      "Inference for Episode 14. Total reward:  -215.32712408094054\n",
      "Inference for Episode 15. Total reward:  -265.8860871305854\n",
      "Inference for Episode 16. Total reward:  -499.27688082083347\n",
      "Inference for Episode 17. Total reward:  -311.1213293184667\n",
      "Inference for Episode 18. Total reward:  -356.4567843029923\n",
      "Inference for Episode 19. Total reward:  -296.48224425794416\n",
      "Mean App Total Completion Time:  108\n",
      "Average Power Consumption per Microservice:  32.655904782431314\n",
      "Percentage Stored in Edge:  0.6789939183608599\n",
      "Percentage Stored in Cloud:  0.32100608163914013\n",
      "Average Execution Time: 0.9747819423675537 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ba82d7-20c6-453a-9cd0-f9ce12775424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -188.24\n",
      "Episode: 2 \t\t Reward: -183.84\n",
      "Episode: 3 \t\t Reward: -112.63\n",
      "Episode: 4 \t\t Reward: -160.38\n",
      "Episode: 5 \t\t Reward: -307.44\n",
      "Episode: 6 \t\t Reward: -199.95\n",
      "Episode: 7 \t\t Reward: -215.53\n",
      "Episode: 8 \t\t Reward: -253.89\n",
      "Episode: 9 \t\t Reward: -170.58\n",
      "Episode: 10 \t\t Reward: -157.43\n",
      "Episode: 11 \t\t Reward: -254.13\n",
      "Episode: 12 \t\t Reward: -235.58\n",
      "Episode: 13 \t\t Reward: -258.53\n",
      "Episode: 14 \t\t Reward: -241.87\n",
      "Episode: 15 \t\t Reward: -205.14\n",
      "Episode: 16 \t\t Reward: -234.64\n",
      "Episode: 17 \t\t Reward: -253.67\n",
      "Episode: 18 \t\t Reward: -215.08\n",
      "Episode: 19 \t\t Reward: -175.65\n",
      "Episode: 20 \t\t Reward: -164.08\n",
      "============================================================================================\n",
      "average test reward : -209.41\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  102\n",
      "Average Power Consumption per Microservice:  36.06393173523491\n",
      "Percentage Stored in Edge:  0.2679055623497872\n",
      "Percentage Stored in Cloud:  0.7320944376502128\n",
      "Average Execution Time: 0.5222997784614563 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e0754-1ac8-4ae5-bdfa-d7ceab77465a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -333.09\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 2 \t\t Reward: -798.11\n",
      "Episode: 3 \t\t Reward: -346.56\n",
      "Episode: 4 \t\t Reward: -329.31\n",
      "Episode: 5 \t\t Reward: -332.3\n",
      "Episode: 6 \t\t Reward: -302.27\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 7 \t\t Reward: -831.08\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 8 \t\t Reward: -745.28\n",
      "Episode: 9 \t\t Reward: -207.71\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 10 \t\t Reward: -769.24\n",
      "Episode: 11 \t\t Reward: -304.94\n",
      "Episode: 12 \t\t Reward: -309.73\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 13 \t\t Reward: -730.56\n",
      "Episode: 14 \t\t Reward: -277.86\n",
      "Episode: 15 \t\t Reward: -252.97\n",
      "Episode: 16 \t\t Reward: -387.31\n",
      "Episode: 17 \t\t Reward: -333.51\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 18 \t\t Reward: -714.56\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 19 \t\t Reward: -809.19\n",
      "Episode: 20 \t\t Reward: -408.59\n",
      "============================================================================================\n",
      "average test reward : -476.21\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  120\n",
      "Average Power Consumption per Microservice:  41.72989891035385\n",
      "Percentage Stored in Edge:  0.2591943564454142\n",
      "Percentage Stored in Cloud:  0.7408056435545858\n",
      "Average Execution Time: 0.7907606363296509 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf47bb8-5f50-4e4d-b43c-f0ab8b6c448a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Episode 0. Total reward:  -237.96129303103007\n",
      "Inference for Episode 1. Total reward:  -449.8333464243831\n",
      "Inference for Episode 2. Total reward:  -380.23526627343125\n",
      "Inference for Episode 3. Total reward:  -284.6408639311147\n",
      "Inference for Episode 4. Total reward:  -281.9515562705067\n",
      "Inference for Episode 5. Total reward:  -343.80527414047833\n",
      "Inference for Episode 6. Total reward:  -324.5498524963633\n",
      "Inference for Episode 7. Total reward:  -223.2887040840402\n",
      "Inference for Episode 8. Total reward:  -262.4782058368305\n",
      "Inference for Episode 9. Total reward:  -258.8905704323865\n",
      "Inference for Episode 10. Total reward:  -406.39684476969387\n",
      "Inference for Episode 11. Total reward:  -313.1268847587424\n",
      "Inference for Episode 12. Total reward:  -225.1302399806952\n",
      "Inference for Episode 13. Total reward:  -329.01489707792996\n",
      "Inference for Episode 14. Total reward:  -173.68367867045208\n",
      "Inference for Episode 15. Total reward:  -356.7498756354991\n",
      "Inference for Episode 16. Total reward:  -417.71523352937743\n",
      "Inference for Episode 17. Total reward:  -247.0749295355787\n",
      "Inference for Episode 18. Total reward:  -253.88917693575738\n",
      "Inference for Episode 19. Total reward:  -321.94500258727226\n",
      "Mean App Total Completion Time:  97\n",
      "Average Power Consumption per Microservice:  36.22396901861061\n",
      "Percentage Stored in Edge:  0.6384043953566901\n",
      "Percentage Stored in Cloud:  0.3615956046433098\n",
      "Average Execution Time: 0.9798043489456176 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4528d0-dca1-46ac-be71-7f599c2fb429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "Inference for Episode 0. Total reward:  -552.5290155135782\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 1. Total reward:  -880.2264517073918\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 2. Total reward:  -831.570831428504\n",
      "Inference for Episode 3. Total reward:  -459.40201280455835\n",
      "Inference for Episode 4. Total reward:  -503.9647443208866\n",
      "Inference for Episode 5. Total reward:  -430.417443933021\n",
      "Inference for Episode 6. Total reward:  -325.5208851052498\n",
      "Inference for Episode 7. Total reward:  -552.9623725890283\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 8. Total reward:  -1024.1383749854108\n",
      "Inference for Episode 9. Total reward:  -483.65873677641554\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 10. Total reward:  -977.8877481762779\n",
      "Inference for Episode 11. Total reward:  -259.1910641773736\n",
      "Inference for Episode 12. Total reward:  -667.4000178473487\n",
      "Inference for Episode 13. Total reward:  -469.619878513182\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 14. Total reward:  -839.8667585006344\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 15. Total reward:  -937.6486594769913\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 16. Total reward:  -720.3062267613441\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 17. Total reward:  -779.6066410457566\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 18. Total reward:  -690.0308014544095\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 19. Total reward:  -739.788074449186\n",
      "Mean App Total Completion Time:  109\n",
      "Average Power Consumption per Microservice:  30.612813968298955\n",
      "Percentage Stored in Edge:  0.7383985094147172\n",
      "Percentage Stored in Cloud:  0.2616014905852828\n",
      "Average Execution Time: 1.45925270318985 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaf8a54-5e58-4904-8e5a-144ee154c6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -519.11\n",
      "Episode: 2 \t\t Reward: -626.69\n",
      "Episode: 3 \t\t Reward: -498.44\n",
      "Episode: 4 \t\t Reward: -555.83\n",
      "Episode: 5 \t\t Reward: -651.28\n",
      "Episode: 6 \t\t Reward: -722.0\n",
      "Episode: 7 \t\t Reward: -324.66\n",
      "Episode: 8 \t\t Reward: -708.31\n",
      "Episode: 9 \t\t Reward: -534.22\n",
      "Episode: 10 \t\t Reward: -856.88\n",
      "Episode: 11 \t\t Reward: -604.82\n",
      "Episode: 12 \t\t Reward: -361.44\n",
      "Episode: 13 \t\t Reward: -604.37\n",
      "Episode: 14 \t\t Reward: -486.24\n",
      "Episode: 15 \t\t Reward: -719.91\n",
      "Episode: 16 \t\t Reward: -688.92\n",
      "Episode: 17 \t\t Reward: -645.84\n",
      "Episode: 18 \t\t Reward: -798.21\n",
      "Episode: 19 \t\t Reward: -494.9\n",
      "Episode: 20 \t\t Reward: -639.15\n",
      "============================================================================================\n",
      "average test reward : -602.06\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  109\n",
      "Average Power Consumption per Microservice:  24.53667442298051\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 6.4689307570457455 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e66c52a-c1ac-4dcb-a106-b6d1d6905c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -204.88\n",
      "Episode: 2 \t\t Reward: -146.26\n",
      "Episode: 3 \t\t Reward: -217.87\n",
      "Episode: 4 \t\t Reward: -135.13\n",
      "Episode: 5 \t\t Reward: -181.93\n",
      "Episode: 6 \t\t Reward: -173.0\n",
      "Episode: 7 \t\t Reward: -258.57\n",
      "Episode: 8 \t\t Reward: -171.23\n",
      "Episode: 9 \t\t Reward: -186.45\n",
      "Episode: 10 \t\t Reward: -185.67\n",
      "Episode: 11 \t\t Reward: -154.73\n",
      "Episode: 12 \t\t Reward: -259.54\n",
      "Episode: 13 \t\t Reward: -110.34\n",
      "Episode: 14 \t\t Reward: -129.69\n",
      "Episode: 15 \t\t Reward: -158.09\n",
      "Episode: 16 \t\t Reward: -121.53\n",
      "Episode: 17 \t\t Reward: -190.4\n",
      "Episode: 18 \t\t Reward: -231.05\n",
      "Episode: 19 \t\t Reward: -218.2\n",
      "Episode: 20 \t\t Reward: -134.3\n",
      "============================================================================================\n",
      "average test reward : -178.44\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  62\n",
      "Average Power Consumption per Microservice:  24.217574721084496\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 2.4450684070587156 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede956f-a911-4864-abc8-8acdb6a8be47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -117.52\n",
      "Episode: 2 \t\t Reward: -133.88\n",
      "Episode: 3 \t\t Reward: -91.62\n",
      "Episode: 4 \t\t Reward: -151.41\n",
      "Episode: 5 \t\t Reward: -90.19\n",
      "Episode: 6 \t\t Reward: -127.58\n",
      "Episode: 7 \t\t Reward: -144.63\n",
      "Episode: 8 \t\t Reward: -108.6\n",
      "Episode: 9 \t\t Reward: -110.99\n",
      "Episode: 10 \t\t Reward: -93.77\n",
      "Episode: 11 \t\t Reward: -86.7\n",
      "Episode: 12 \t\t Reward: -105.78\n",
      "Episode: 13 \t\t Reward: -106.94\n",
      "Episode: 14 \t\t Reward: -105.14\n",
      "Episode: 15 \t\t Reward: -95.54\n",
      "Episode: 16 \t\t Reward: -108.37\n",
      "Episode: 17 \t\t Reward: -93.28\n",
      "Episode: 18 \t\t Reward: -106.84\n",
      "Episode: 19 \t\t Reward: -112.13\n",
      "Episode: 20 \t\t Reward: -91.93\n",
      "============================================================================================\n",
      "average test reward : -109.14\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  67\n",
      "Average Power Consumption per Microservice:  35.439000423617124\n",
      "Percentage Stored in Edge:  0.21296969519904782\n",
      "Percentage Stored in Cloud:  0.7870303048009522\n",
      "Average Execution Time: 0.44994981288909913 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f5fda4-54c5-4d6a-b49a-cf729efb962d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "Inference for Episode 0. Total reward:  -213.0221332110658\n",
      "Inference for Episode 1. Total reward:  -187.55316407411473\n",
      "Inference for Episode 2. Total reward:  -131.292844321774\n",
      "Inference for Episode 3. Total reward:  -159.05473312745582\n",
      "Inference for Episode 4. Total reward:  -152.9139125658507\n",
      "Inference for Episode 5. Total reward:  -174.87530633870793\n",
      "Inference for Episode 6. Total reward:  -197.35352160104415\n",
      "Inference for Episode 7. Total reward:  -216.48465749485365\n",
      "Inference for Episode 8. Total reward:  -133.7271518074988\n",
      "Inference for Episode 9. Total reward:  -135.70632472706302\n",
      "Inference for Episode 10. Total reward:  -158.6575478130313\n",
      "Inference for Episode 11. Total reward:  -137.73492453408426\n",
      "Inference for Episode 12. Total reward:  -136.02151894743807\n",
      "Inference for Episode 13. Total reward:  -113.82949392924739\n",
      "Inference for Episode 14. Total reward:  -149.26391926368794\n",
      "Inference for Episode 15. Total reward:  -137.379764037816\n",
      "Inference for Episode 16. Total reward:  -147.38490800953707\n",
      "Inference for Episode 17. Total reward:  -162.65294541753428\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 18. Total reward:  -655.4415254812378\n",
      "Inference for Episode 19. Total reward:  -130.17599598213135\n",
      "Mean App Total Completion Time:  66\n",
      "Average Power Consumption per Microservice:  49.31929651902628\n",
      "Percentage Stored in Edge:  0.4777712755710977\n",
      "Percentage Stored in Cloud:  0.5222287244289023\n",
      "Average Execution Time: 0.7689069151878357 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c206dac-5615-4ac3-bc32-b1685ba40962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -39.88\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -41.3\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -43.14\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -39.63\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -47.68\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -39.29\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -40.72\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -59.69\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -40.16\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -34.66\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -47.68\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -46.43\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -45.34\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -51.97\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -50.1\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -42.68\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -46.41\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -42.6\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -46.95\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -52.98\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -44.96\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  15\n",
      "Average Power Consumption per Microservice:  31.514151047812913\n",
      "Percentage Stored in Edge:  0.2900070500097189\n",
      "Percentage Stored in Cloud:  0.7099929499902811\n",
      "Average Execution Time: 0.2608933925628662 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c702c-9bfa-4db2-b7c4-83063e48356d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 0. Total reward:  -54.17129770939247\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 1. Total reward:  -58.43528177685089\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 2. Total reward:  -63.91158605632637\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 3. Total reward:  -46.891393979176776\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 4. Total reward:  -60.946874755043346\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 5. Total reward:  -58.09813092639786\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 6. Total reward:  -65.92372576625755\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 7. Total reward:  -69.42770603239128\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 8. Total reward:  -57.61029619892923\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 9. Total reward:  -53.210772707549104\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 10. Total reward:  -61.40110716726849\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 11. Total reward:  -56.30413064970464\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 12. Total reward:  -65.53748328396576\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 13. Total reward:  -48.04942856095501\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 14. Total reward:  -52.701679029538575\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 15. Total reward:  -59.615089581032024\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 16. Total reward:  -68.01945292718666\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 17. Total reward:  -58.526913754148836\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 18. Total reward:  -77.9993341708891\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 19. Total reward:  -52.22906300477031\n",
      "Mean App Total Completion Time:  18\n",
      "Average Power Consumption per Microservice:  52.008893567990306\n",
      "Percentage Stored in Edge:  0.24421420129183155\n",
      "Percentage Stored in Cloud:  0.7557857987081684\n",
      "Average Execution Time: 0.3912812113761902 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b298c888-3a00-4d31-b8a6-d285a5c53844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 0. Total reward:  -75.32796468503162\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 1. Total reward:  -55.703465559539815\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 2. Total reward:  -51.11423722400824\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 3. Total reward:  -50.79175852086167\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 4. Total reward:  -63.964159436623994\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 5. Total reward:  -55.56119642208478\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 6. Total reward:  -49.30955626871823\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 7. Total reward:  -44.3319862855647\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 8. Total reward:  -46.15597404500008\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 9. Total reward:  -58.84316992157786\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 10. Total reward:  -52.90488506661014\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 11. Total reward:  -52.67329153098548\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 12. Total reward:  -53.728400867567615\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 13. Total reward:  -59.79582446187228\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 14. Total reward:  -59.80487612889435\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 15. Total reward:  -54.18600253007092\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 16. Total reward:  -47.214151993191756\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 17. Total reward:  -60.500144143707935\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 18. Total reward:  -64.03017521579376\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Inference for Episode 19. Total reward:  -69.1207729742217\n",
      "Mean App Total Completion Time:  18\n",
      "Average Power Consumption per Microservice:  47.99258829209889\n",
      "Percentage Stored in Edge:  0.23441974128093163\n",
      "Percentage Stored in Cloud:  0.7655802587190684\n",
      "Average Execution Time: 0.3312347173690796 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44e6b9c-e864-4116-bd39-fe941af8c15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -43.65\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -52.21\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -50.99\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -51.11\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -51.23\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -40.1\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -52.68\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -49.18\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -46.36\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -46.44\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -45.05\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -45.74\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -55.54\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -53.87\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -51.01\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -41.39\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -33.52\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -46.51\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -49.26\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -49.46\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_1.0_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -47.77\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  11\n",
      "Average Power Consumption per Microservice:  21.205245505423623\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 0.7248676419258118 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee5b61e-9354-4a8c-a50e-c6224b36042e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -72.86\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -110.96\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -76.95\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -82.61\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -77.4\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -147.29\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -98.88\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -134.2\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -149.51\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -121.58\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -105.08\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -105.75\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -83.28\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -104.07\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -84.33\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -71.55\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -114.9\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -115.25\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -91.22\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -111.83\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -102.97\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  42\n",
      "Average Power Consumption per Microservice:  25.2130340769062\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 1.38954838514328 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b62c9d-a960-4d3e-a95b-a596de42cdda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 0. Total reward:  -83.26785610151553\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 1. Total reward:  -94.48237157402107\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 2. Total reward:  -99.14699988322339\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 3. Total reward:  -132.59994918044086\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 4. Total reward:  -105.12087991994305\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 5. Total reward:  -82.36613363275697\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 6. Total reward:  -129.779460339284\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 7. Total reward:  -126.9210085945704\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 8. Total reward:  -113.88170208958036\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 9. Total reward:  -100.1750868287368\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 10. Total reward:  -93.82462168147225\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 11. Total reward:  -98.89951562777559\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 12. Total reward:  -89.81241911105023\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 13. Total reward:  -89.6579550280548\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 14. Total reward:  -121.08769869517216\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 15. Total reward:  -90.96460757220318\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 16. Total reward:  -69.22020356063355\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 17. Total reward:  -103.8880076696725\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 18. Total reward:  -82.54935301577858\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Inference for Episode 19. Total reward:  -72.55971042407228\n",
      "Mean App Total Completion Time:  49\n",
      "Average Power Consumption per Microservice:  65.30482438327014\n",
      "Percentage Stored in Edge:  0.30414882111664\n",
      "Percentage Stored in Cloud:  0.69585117888336\n",
      "Average Execution Time: 0.5097500085830688 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c729e13-084a-4fe8-b54b-ab2f9eac9622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -77.96\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -63.15\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -51.96\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -51.19\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -83.74\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -72.61\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -56.02\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -76.36\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -48.53\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -78.64\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -71.91\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -61.29\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -65.95\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -62.52\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -79.54\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -70.03\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -72.34\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -72.73\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -65.64\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -60.32\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.08_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -67.12\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  45\n",
      "Average Power Consumption per Microservice:  37.47237449428466\n",
      "Percentage Stored in Edge:  0.20075699445867629\n",
      "Percentage Stored in Cloud:  0.7992430055413238\n",
      "Average Execution Time: 0.37833997011184695 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a4612-47a0-4a94-b304-d537aa0a5f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -92.49\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -94.1\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -84.53\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -79.01\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -80.49\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -75.11\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -93.25\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -104.73\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -92.24\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -76.45\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -127.1\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -68.96\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -119.52\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -95.42\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -67.3\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -96.78\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -118.06\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -66.87\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -114.75\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -79.3\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -91.32\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  53\n",
      "Average Power Consumption per Microservice:  35.218381174361646\n",
      "Percentage Stored in Edge:  0.19876857064789816\n",
      "Percentage Stored in Cloud:  0.8012314293521019\n",
      "Average Execution Time: 0.390950882434845 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81335bef-3016-41e6-ac50-c194c42daab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 0. Total reward:  -163.36957836378267\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 1. Total reward:  -138.4294623526873\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 2. Total reward:  -140.95058787416488\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 3. Total reward:  -116.62670381703501\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 4. Total reward:  -145.69060213784553\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 5. Total reward:  -117.36988151876851\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 6. Total reward:  -144.43118045082792\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 7. Total reward:  -150.03748247444463\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 8. Total reward:  -139.70544518548488\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 9. Total reward:  -138.93934067288836\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 10. Total reward:  -145.19736593667824\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 11. Total reward:  -99.27474470441406\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 12. Total reward:  -155.1308793280319\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 13. Total reward:  -155.70131838304815\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 14. Total reward:  -141.10369686746608\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 15. Total reward:  -157.91319753093236\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 16. Total reward:  -105.3904257866142\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 17. Total reward:  -150.25036700297827\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 18. Total reward:  -124.65457046817457\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Inference for Episode 19. Total reward:  -90.99199529461666\n",
      "Mean App Total Completion Time:  62\n",
      "Average Power Consumption per Microservice:  63.1930473698447\n",
      "Percentage Stored in Edge:  0.32359995957023596\n",
      "Percentage Stored in Cloud:  0.6764000404297641\n",
      "Average Execution Time: 0.6136167168617248 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96aad23-8009-4508-8da5-a1b8c9fe96e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -113.58\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -123.51\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -108.5\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -132.55\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -128.43\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -157.07\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -143.99\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -178.39\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -181.42\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -101.28\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -153.94\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -186.7\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -188.93\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -73.36\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -95.77\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -134.59\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -131.77\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -167.56\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -92.52\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -122.96\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_2.99_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -135.84\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  48\n",
      "Average Power Consumption per Microservice:  23.25978566285214\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 1.894259750843048 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3415c806-3546-4b59-8c64-152dcc8b7e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -211.84\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -198.74\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -205.62\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -160.95\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -200.43\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -224.39\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -176.4\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -203.97\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -168.24\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -181.77\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -199.43\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -160.1\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -182.58\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -194.56\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -181.28\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -186.16\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -227.05\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -162.09\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -265.01\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -185.79\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -193.82\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  65\n",
      "Average Power Consumption per Microservice:  24.910207452441405\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 2.368868660926819 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a58249-c4ef-4285-8ff8-39368c75bd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 0. Total reward:  -166.92299886089188\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 1. Total reward:  -263.8824141364455\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 2. Total reward:  -154.72928215079452\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 3. Total reward:  -221.5449228356122\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 4. Total reward:  -185.23207288755026\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 5. Total reward:  -102.61981085768197\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 6. Total reward:  -164.60658922812257\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 7. Total reward:  -136.4453112312205\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 8. Total reward:  -139.75539133123587\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 9. Total reward:  -137.8038582502226\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 10. Total reward:  -182.16489854687725\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 11. Total reward:  -158.32912505912367\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 12. Total reward:  -207.06330000547044\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 13. Total reward:  -146.26989135556468\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 14. Total reward:  -182.70407099364846\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 15. Total reward:  -153.13072505783563\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 16. Total reward:  -134.26775328549755\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 17. Total reward:  -124.87470584573884\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 18. Total reward:  -136.4821205770328\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Inference for Episode 19. Total reward:  -149.4711968442264\n",
      "Mean App Total Completion Time:  67\n",
      "Average Power Consumption per Microservice:  46.528611959389906\n",
      "Percentage Stored in Edge:  0.4463843016933591\n",
      "Percentage Stored in Cloud:  0.5536156983066409\n",
      "Average Execution Time: 0.7621118545532226 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c73a2c4-9214-456c-ba2f-43e911efb21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -113.62\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -98.49\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -98.48\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -86.53\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -137.19\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -128.58\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -94.28\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -141.81\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -88.21\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -119.63\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -94.19\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -102.79\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -121.34\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -106.23\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -111.53\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -94.35\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -95.35\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -152.65\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -102.65\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -113.7\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -110.08\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  67\n",
      "Average Power Consumption per Microservice:  33.0795992373383\n",
      "Percentage Stored in Edge:  0.21161441010897558\n",
      "Percentage Stored in Cloud:  0.7883855898910245\n",
      "Average Execution Time: 0.40414254665374755 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac502a0-711e-4455-8c42-6db871a2f9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -142.72\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -167.74\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -142.03\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -214.02\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -134.81\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -203.69\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -200.01\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -126.2\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -220.13\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -257.32\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -201.66\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -214.09\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -174.08\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -165.76\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -157.71\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -182.74\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -142.85\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -175.4\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -145.38\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -160.69\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_3.89_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -176.45\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  59\n",
      "Average Power Consumption per Microservice:  21.288943912904173\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 2.306941819190979 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc99513-77f8-428c-a040-1f8a3554a93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -277.99\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -225.95\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -202.34\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -261.52\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -312.04\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -328.55\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -417.76\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -227.56\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -234.7\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -259.62\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -241.48\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -322.39\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -248.08\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -264.76\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -246.76\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -151.71\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -204.37\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -210.49\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -243.81\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -398.57\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -264.02\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  79\n",
      "Average Power Consumption per Microservice:  24.93270183194417\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 3.0526456236839294 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde675e4-8829-4000-8476-68b663fdf8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -220.06\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -337.01\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -283.98\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -344.27\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -233.19\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -315.44\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -340.25\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -275.42\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -208.67\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -270.47\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -193.52\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -247.36\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -235.47\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -271.04\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -238.1\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -384.33\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -192.82\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -213.18\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -233.26\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -242.28\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -264.01\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  80\n",
      "Average Power Consumption per Microservice:  21.79411101713048\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 3.002393114566803 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29999fd-6e1f-429b-9328-3b1824d0233f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -190.36\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -289.37\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -318.6\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -381.42\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -208.21\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -196.0\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -180.82\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -295.6\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -291.18\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -311.03\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -208.25\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -181.84\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -217.87\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -183.58\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -286.8\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -198.11\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -204.86\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -168.63\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -261.67\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -214.85\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -239.45\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  71\n",
      "Average Power Consumption per Microservice:  24.34524372374439\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 3.096560871601105 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fdf6bb-2c20-43bb-9d86-5ad6de17d068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 0. Total reward:  -218.30600370495668\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 1. Total reward:  -251.9076620631424\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 2. Total reward:  -232.71810411302943\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 3. Total reward:  -197.47090879537416\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 4. Total reward:  -289.84832776179405\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 5. Total reward:  -262.97886013447834\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 6. Total reward:  -292.1634456565808\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 7. Total reward:  -237.17483040461389\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 8. Total reward:  -230.71557893406637\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 9. Total reward:  -274.5096345329848\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 10. Total reward:  -240.12969800875973\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 11. Total reward:  -235.6088183323759\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 12. Total reward:  -352.42898073829815\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 13. Total reward:  -270.54202813493987\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 14. Total reward:  -271.5635341213843\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 15. Total reward:  -330.9061215394841\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 16. Total reward:  -201.49232611842052\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 17. Total reward:  -241.38095448399338\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 18. Total reward:  -256.51610474707473\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 19. Total reward:  -211.1309216026894\n",
      "Mean App Total Completion Time:  97\n",
      "Average Power Consumption per Microservice:  51.25047970663689\n",
      "Percentage Stored in Edge:  0.44109227856782446\n",
      "Percentage Stored in Cloud:  0.5589077214321755\n",
      "Average Execution Time: 0.945048189163208 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e747a0b1-3292-481b-8acd-b06f61ee4f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 0. Total reward:  -245.0434692662434\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 1. Total reward:  -241.8620906044723\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 2. Total reward:  -171.30699685299953\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 3. Total reward:  -276.802708714143\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 4. Total reward:  -175.40480524833745\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 5. Total reward:  -230.24670146203147\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 6. Total reward:  -246.89278055895713\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 7. Total reward:  -274.38906445842224\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 8. Total reward:  -154.1090082322751\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 9. Total reward:  -203.1297656005393\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 10. Total reward:  -191.11947607316125\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 11. Total reward:  -226.43154346955214\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 12. Total reward:  -240.42338040626268\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 13. Total reward:  -198.88260292491194\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 14. Total reward:  -202.06059974358084\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 15. Total reward:  -205.38059772449338\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 16. Total reward:  -227.22231490116192\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 17. Total reward:  -327.8887638275171\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 18. Total reward:  -210.70867375545927\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Inference for Episode 19. Total reward:  -325.38475495141387\n",
      "Mean App Total Completion Time:  84\n",
      "Average Power Consumption per Microservice:  47.119131251443484\n",
      "Percentage Stored in Edge:  0.43272381215839234\n",
      "Percentage Stored in Cloud:  0.5672761878416076\n",
      "Average Execution Time: 0.9374902367591857 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb505b1f-0c14-4c97-b484-e362e7fd9c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -133.25\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -131.4\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -114.3\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -162.04\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -173.11\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -193.62\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -210.28\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -166.84\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -141.12\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -194.93\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -126.8\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -148.68\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -130.41\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -131.53\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -176.21\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -165.86\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -178.91\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -166.66\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -133.69\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -144.49\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_5.45_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -156.21\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  83\n",
      "Average Power Consumption per Microservice:  37.13741499848298\n",
      "Percentage Stored in Edge:  0.19402571691966655\n",
      "Percentage Stored in Cloud:  0.8059742830803335\n",
      "Average Execution Time: 0.4671107053756714 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488308c7-0e62-4b64-8360-881ebe6e7571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -170.0\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -139.01\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -117.99\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -137.22\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -157.41\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -150.04\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -115.75\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -151.79\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -164.72\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -149.05\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -184.25\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -190.88\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -120.69\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -143.88\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -117.93\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -145.76\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -141.55\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -133.79\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -191.95\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -147.73\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -148.57\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  85\n",
      "Average Power Consumption per Microservice:  30.867596844756694\n",
      "Percentage Stored in Edge:  0.20355740829453722\n",
      "Percentage Stored in Cloud:  0.7964425917054628\n",
      "Average Execution Time: 0.4907527446746826 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6651fa4d-f667-4b0f-91d2-7907c1f835aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -137.68\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -146.17\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -128.99\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -176.82\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -195.88\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -141.25\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -171.74\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -183.34\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -123.33\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -213.77\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -199.52\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -175.23\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -142.67\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -227.55\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -211.79\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -214.24\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -161.68\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -164.99\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -148.38\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -189.18\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -172.71\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  89\n",
      "Average Power Consumption per Microservice:  36.248036788279975\n",
      "Percentage Stored in Edge:  0.23588871238570713\n",
      "Percentage Stored in Cloud:  0.7641112876142928\n",
      "Average Execution Time: 0.48557775020599364 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cbbab9-d655-4a99-a640-04a5772914aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -180.22\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -178.85\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -184.12\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -204.39\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -156.79\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -188.85\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -185.04\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -149.05\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -164.4\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -188.75\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -125.65\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -126.69\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -159.23\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -143.69\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -228.02\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -118.06\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -157.61\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -142.76\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -205.3\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -147.06\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -166.73\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  90\n",
      "Average Power Consumption per Microservice:  33.18722464575525\n",
      "Percentage Stored in Edge:  0.2386296056382609\n",
      "Percentage Stored in Cloud:  0.7613703943617391\n",
      "Average Execution Time: 0.5238219022750854 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a805c102-8f55-4244-8459-59926e452d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 0. Total reward:  -183.43771726468557\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 1. Total reward:  -217.0635197910731\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 2. Total reward:  -262.95772835985315\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 3. Total reward:  -227.04658447478835\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 4. Total reward:  -235.56879531319132\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 5. Total reward:  -249.3960540122544\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 6. Total reward:  -221.64378887805844\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 7. Total reward:  -220.22464594400375\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 8. Total reward:  -253.72627870877596\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 9. Total reward:  -743.3720228720231\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 10. Total reward:  -202.08317516041706\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 11. Total reward:  -220.59078368100737\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 12. Total reward:  -275.32751299112385\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 13. Total reward:  -306.94513317594726\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 14. Total reward:  -314.0372032792469\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 15. Total reward:  -316.33431082989716\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 16. Total reward:  -167.5106931823926\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 17. Total reward:  -271.6692033244806\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 18. Total reward:  -235.79482650906652\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 19. Total reward:  -714.2693949574955\n",
      "Mean App Total Completion Time:  88\n",
      "Average Power Consumption per Microservice:  36.50124360735208\n",
      "Percentage Stored in Edge:  0.5586560864973117\n",
      "Percentage Stored in Cloud:  0.4413439135026883\n",
      "Average Execution Time: 0.9974346041679383 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352e7db-c05c-4fc1-ac3a-647e18906b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 0. Total reward:  -332.30771199061553\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 1. Total reward:  -315.3053424485641\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 2. Total reward:  -194.41632806638776\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 3. Total reward:  -656.9886851380924\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 4. Total reward:  -274.2396441196344\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 5. Total reward:  -293.32915267510026\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 6. Total reward:  -253.69190122039134\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 7. Total reward:  -277.3793109426389\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 8. Total reward:  -277.5587082736029\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 9. Total reward:  -246.79379921441102\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 10. Total reward:  -209.3379896461338\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 11. Total reward:  -280.65654968892954\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 12. Total reward:  -250.06784269229144\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 13. Total reward:  -254.39400717305458\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 14. Total reward:  -200.9583237329859\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 15. Total reward:  -187.4355399574915\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 16. Total reward:  -275.1131119643578\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 17. Total reward:  -259.46673529966705\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 18. Total reward:  -268.9916393793931\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Inference for Episode 19. Total reward:  -249.2773247456088\n",
      "Mean App Total Completion Time:  94\n",
      "Average Power Consumption per Microservice:  41.380743511374945\n",
      "Percentage Stored in Edge:  0.565170087580364\n",
      "Percentage Stored in Cloud:  0.434829912419636\n",
      "Average Execution Time: 0.9912686586380005 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0a82d9-3bcb-4add-b74c-98e1e48f8bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -201.15\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -380.92\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -258.63\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -236.24\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -218.24\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -309.94\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -387.52\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -318.62\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -181.84\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -290.97\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -333.33\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -299.77\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -259.58\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -278.71\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -261.11\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -318.41\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -269.8\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -231.27\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -326.16\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -386.34\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -287.43\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  84\n",
      "Average Power Consumption per Microservice:  21.711481310165304\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 3.2613751530647277 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c76fbb1-5e9b-4e78-b9f0-dff862741ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -285.84\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -277.53\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -417.1\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -203.22\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -261.77\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -216.74\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -435.5\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -322.24\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -321.82\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -326.24\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -233.58\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -224.52\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -298.9\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -329.95\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -235.46\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -292.6\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -270.14\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -250.9\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -255.29\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -279.73\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -286.95\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  84\n",
      "Average Power Consumption per Microservice:  22.309229783603584\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 3.5041579246520995 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6089ab-3472-4555-b416-951a91ad9c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -359.55\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -172.85\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -274.9\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -298.17\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -202.1\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -241.59\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -273.19\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -348.99\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -206.49\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -269.36\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -280.42\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -348.09\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -225.43\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -224.88\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -348.31\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -346.74\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -207.96\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -369.32\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -352.25\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -204.33\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_6.14_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -277.75\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  81\n",
      "Average Power Consumption per Microservice:  24.25178667198073\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 3.262547218799591 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee6fc9-49e4-4ecd-b4cc-3d5d5309093e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -469.62\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -443.68\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -292.16\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -368.19\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -335.72\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -412.81\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -492.51\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -406.13\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -342.36\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -447.04\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -472.41\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -332.68\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -342.83\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -330.66\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -336.99\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -407.79\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -468.53\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -601.63\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -404.1\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -338.19\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -402.3\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  97\n",
      "Average Power Consumption per Microservice:  21.088300601657146\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 5.5438225865364075 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f30e8-5e28-4b42-892e-51d6c08de68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -297.39\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -415.51\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -356.52\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -338.56\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -368.94\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -642.17\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -422.15\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -406.76\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -399.49\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -389.03\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -350.54\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -313.93\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -411.22\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -418.28\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -496.24\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -523.63\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -344.5\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -399.05\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -391.81\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -352.89\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -401.93\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  98\n",
      "Average Power Consumption per Microservice:  20.797966607305202\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 5.854538249969482 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6ba22e-4fcd-48fc-9496-5eec1cb2a07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 0. Total reward:  -351.94188798535424\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 1. Total reward:  -242.32790081401168\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 2. Total reward:  -763.4741793661437\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 3. Total reward:  -335.2330989252825\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 4. Total reward:  -693.0064500511783\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 5. Total reward:  -417.3324716916926\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 6. Total reward:  -413.33160282494697\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 7. Total reward:  -328.189870127592\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 8. Total reward:  -477.0940840075182\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 9. Total reward:  -965.6376767086501\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 10. Total reward:  -288.2547354343926\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 11. Total reward:  -742.161591387374\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 12. Total reward:  -772.60808848488\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 13. Total reward:  -303.8537502626977\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 14. Total reward:  -714.0361270110533\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 15. Total reward:  -781.2044114168023\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 16. Total reward:  -830.1516597629076\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 17. Total reward:  -850.5761104107994\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 18. Total reward:  -715.7771902056774\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 19. Total reward:  -428.69174974409367\n",
      "Mean App Total Completion Time:  106\n",
      "Average Power Consumption per Microservice:  30.319221896580792\n",
      "Percentage Stored in Edge:  0.6723593793932354\n",
      "Percentage Stored in Cloud:  0.3276406206067646\n",
      "Average Execution Time: 1.322884976863861 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb2ff3c-65af-411f-8b92-f1ea144bccc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 0. Total reward:  -272.99378979437574\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 1. Total reward:  -376.4999804062764\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 2. Total reward:  -505.35540096915133\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 3. Total reward:  -319.3723185927426\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 4. Total reward:  -385.26302955809615\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 5. Total reward:  -370.27441439668996\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 6. Total reward:  -777.6902227105459\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 7. Total reward:  -372.90047877200055\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 8. Total reward:  -970.8936843446912\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 9. Total reward:  -321.0751505180802\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 10. Total reward:  -706.8930090204518\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 11. Total reward:  -333.55902733553876\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 12. Total reward:  -658.6265013414449\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 13. Total reward:  -346.01751923390674\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 14. Total reward:  -874.148061839431\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 15. Total reward:  -368.1699555537615\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 16. Total reward:  -398.23681761162175\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 17. Total reward:  -428.089169668292\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 18. Total reward:  -739.7297683290485\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Inference for Episode 19. Total reward:  -420.5905359617794\n",
      "Mean App Total Completion Time:  104\n",
      "Average Power Consumption per Microservice:  28.53680132161348\n",
      "Percentage Stored in Edge:  0.6915142929311558\n",
      "Percentage Stored in Cloud:  0.30848570706884415\n",
      "Average Execution Time: 1.3730059742927552 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05d9790-7453-4548-b90c-0d754722bd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -314.67\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -263.27\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -257.54\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -303.54\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -289.25\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -211.59\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -281.65\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -231.42\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -311.48\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 10 \t\t Reward: -669.06\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -196.11\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -223.72\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -217.43\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -289.15\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -203.75\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -277.83\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -240.94\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -242.4\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 19 \t\t Reward: -614.09\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -359.68\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -299.93\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  113\n",
      "Average Power Consumption per Microservice:  34.43282600681461\n",
      "Percentage Stored in Edge:  0.21769507178504305\n",
      "Percentage Stored in Cloud:  0.782304928214957\n",
      "Average Execution Time: 0.668655526638031 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff617535-fc3b-4dfe-9611-389c19e7b9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -256.55\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -258.39\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -153.35\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 4 \t\t Reward: -685.8\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -222.49\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 6 \t\t Reward: -676.9\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 7 \t\t Reward: -670.93\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -169.42\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 9 \t\t Reward: -745.28\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -191.07\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -199.36\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -247.35\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -247.17\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -230.95\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 15 \t\t Reward: -716.39\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -247.01\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -174.47\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 18 \t\t Reward: -686.09\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 19 \t\t Reward: -647.74\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -234.7\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -383.07\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  100\n",
      "Average Power Consumption per Microservice:  31.85238286693823\n",
      "Percentage Stored in Edge:  0.19822451578460099\n",
      "Percentage Stored in Cloud:  0.801775484215399\n",
      "Average Execution Time: 0.6736823201179505 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff81007c-f44a-45ab-bd75-c92bee0685a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 1 \t\t Reward: -655.37\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -229.54\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -203.71\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -291.47\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 5 \t\t Reward: -680.38\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 6 \t\t Reward: -677.13\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -284.76\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -177.57\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -195.47\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 10 \t\t Reward: -718.11\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -199.01\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -177.05\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -259.38\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 14 \t\t Reward: -766.07\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -192.17\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -233.79\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 17 \t\t Reward: -665.71\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -248.43\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -249.16\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 20 \t\t Reward: -703.16\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -390.37\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  106\n",
      "Average Power Consumption per Microservice:  35.76028902395157\n",
      "Percentage Stored in Edge:  0.2245101644369866\n",
      "Percentage Stored in Cloud:  0.7754898355630134\n",
      "Average Execution Time: 0.6786290884017945 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b590184-612c-448e-9ca3-a25ec5464709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 1 \t\t Reward: -657.77\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -194.25\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -284.92\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -258.21\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -213.43\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -194.0\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -209.23\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -186.7\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -221.25\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 10 \t\t Reward: -615.92\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 11 \t\t Reward: -618.6\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -177.21\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -182.11\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -252.05\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 15 \t\t Reward: -686.89\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -239.55\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -166.34\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 18 \t\t Reward: -604.73\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -179.07\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -195.45\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -316.88\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  99\n",
      "Average Power Consumption per Microservice:  34.12203355253039\n",
      "Percentage Stored in Edge:  0.18817685629672207\n",
      "Percentage Stored in Cloud:  0.8118231437032779\n",
      "Average Execution Time: 0.6802196979522706 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36a807d-ec42-47e2-bfb9-8c93be11995f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 1 \t\t Reward: -691.32\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -257.37\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 3 \t\t Reward: -626.72\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 4 \t\t Reward: -694.03\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -357.43\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 6 \t\t Reward: -746.94\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -255.11\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -327.17\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 9 \t\t Reward: -793.36\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 10 \t\t Reward: -672.36\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 11 \t\t Reward: -601.15\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 12 \t\t Reward: -726.44\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 13 \t\t Reward: -814.39\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 14 \t\t Reward: -588.39\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 15 \t\t Reward: -821.84\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 16 \t\t Reward: -852.8\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -295.17\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -268.62\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -342.22\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -294.69\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -551.38\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  115\n",
      "Average Power Consumption per Microservice:  38.96670436027372\n",
      "Percentage Stored in Edge:  0.26758811800728344\n",
      "Percentage Stored in Cloud:  0.7324118819927166\n",
      "Average Execution Time: 0.79598308801651 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568d5533-45bd-4c7c-a37b-c6e5f1677ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -252.68\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 2 \t\t Reward: -780.76\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 3 \t\t Reward: -762.38\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -384.6\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -201.53\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -269.67\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -259.27\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -271.34\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -257.49\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -273.1\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -189.81\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -425.67\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -243.31\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -231.22\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -284.77\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -215.26\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -308.41\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -221.68\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -249.51\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -332.99\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -320.77\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  114\n",
      "Average Power Consumption per Microservice:  34.8334357951493\n",
      "Percentage Stored in Edge:  0.2735511427783184\n",
      "Percentage Stored in Cloud:  0.7264488572216816\n",
      "Average Execution Time: 0.7616782426834107 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5230319-4dea-462b-9029-89d35843fc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 1 \t\t Reward: -797.14\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -230.27\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -359.27\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -325.8\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 5 \t\t Reward: -709.82\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -247.67\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -207.96\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -235.06\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 9 \t\t Reward: -851.36\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -194.84\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -327.21\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -316.62\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -283.66\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -291.38\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -261.45\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 16 \t\t Reward: -710.28\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -286.35\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -399.25\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -278.05\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -284.98\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -379.92\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  121\n",
      "Average Power Consumption per Microservice:  36.97294650766359\n",
      "Percentage Stored in Edge:  0.2801414824852842\n",
      "Percentage Stored in Cloud:  0.7198585175147157\n",
      "Average Execution Time: 0.7126380562782287 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9530a0d-0ff4-4a37-a076-2e01501b5d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 0. Total reward:  -410.59847101216235\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 1. Total reward:  -386.64006093647777\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 2. Total reward:  -472.44852765590207\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 3. Total reward:  -554.5260168775882\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 4. Total reward:  -402.93331171519316\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 5. Total reward:  -306.63545925485164\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 6. Total reward:  -381.248497373726\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 7. Total reward:  -369.48334024676774\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 8. Total reward:  -612.2481174350347\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 9. Total reward:  -376.05531610658096\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 10. Total reward:  -486.72645710161447\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 11. Total reward:  -577.7166748791315\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 12. Total reward:  -540.8761343517798\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 13. Total reward:  -522.2907754774014\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 14. Total reward:  -338.5867013925777\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 15. Total reward:  -399.62165031533834\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 16. Total reward:  -379.65872380696055\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 17. Total reward:  -973.330943295789\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 18. Total reward:  -359.2977727780668\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Inference for Episode 19. Total reward:  -469.4344016478135\n",
      "Mean App Total Completion Time:  118\n",
      "Average Power Consumption per Microservice:  32.13218699474645\n",
      "Percentage Stored in Edge:  0.7209352876798991\n",
      "Percentage Stored in Cloud:  0.2790647123201009\n",
      "Average Execution Time: 1.5663593053817748 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edd2f44-bfdd-4ab0-bd2f-fd1bf73ea746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 0. Total reward:  -288.3612571644989\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 1. Total reward:  -974.7065148303136\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 2. Total reward:  -388.6595269310856\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 3. Total reward:  -459.51022998897224\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 4. Total reward:  -394.1209190751762\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 5. Total reward:  -401.4900807844199\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 6. Total reward:  -305.152872651353\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 7. Total reward:  -299.6627037865734\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 8. Total reward:  -257.2669524043466\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 9. Total reward:  -477.9209278131173\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 10. Total reward:  -369.1739717063624\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 11. Total reward:  -364.40603856200505\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 12. Total reward:  -343.3447684611225\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 13. Total reward:  -407.8310342678654\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 14. Total reward:  -261.9631642893163\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 15. Total reward:  -357.9826842744525\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 16. Total reward:  -470.25749516754223\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 17. Total reward:  -478.5058266672752\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 18. Total reward:  -314.1695902325267\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 19. Total reward:  -388.47954265330446\n",
      "Mean App Total Completion Time:  110\n",
      "Average Power Consumption per Microservice:  31.192913548575\n",
      "Percentage Stored in Edge:  0.7327983967940858\n",
      "Percentage Stored in Cloud:  0.26720160320591424\n",
      "Average Execution Time: 1.2505234837532044 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39695834-a14e-476c-949a-f7678235298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 0. Total reward:  -365.23853310738974\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 1. Total reward:  -400.0219508411395\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 2. Total reward:  -307.8916729845224\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 3. Total reward:  -554.7512713239936\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 4. Total reward:  -450.6876292083561\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 5. Total reward:  -341.3908145073144\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 6. Total reward:  -245.06690273803838\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 7. Total reward:  -406.18866560655835\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 8. Total reward:  -269.6222822699218\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 9. Total reward:  -439.0031909406895\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 10. Total reward:  -305.56046525112697\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 11. Total reward:  -298.331169712189\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 12. Total reward:  -336.8821311382579\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 13. Total reward:  -588.5572809973017\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 14. Total reward:  -405.85986309445923\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 15. Total reward:  -420.4699864112715\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 16. Total reward:  -269.4775042203978\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 17. Total reward:  -439.1758083764096\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 18. Total reward:  -264.6347110145984\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 19. Total reward:  -359.41623617569826\n",
      "Mean App Total Completion Time:  112\n",
      "Average Power Consumption per Microservice:  27.540833950539003\n",
      "Percentage Stored in Edge:  0.7161611706432385\n",
      "Percentage Stored in Cloud:  0.28383882935676147\n",
      "Average Execution Time: 1.320871353149414 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8880e328-a9ea-4cc9-a6a3-c2cb1d717d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 0. Total reward:  -507.97584344627177\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 1. Total reward:  -913.377358482963\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 2. Total reward:  -410.00599154846185\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 3. Total reward:  -470.26747792299614\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 4. Total reward:  -925.8361630596589\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 5. Total reward:  -357.8400189647977\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 6. Total reward:  -763.7840721693981\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 7. Total reward:  -455.647740345989\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 8. Total reward:  -511.5892833357857\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 9. Total reward:  -424.0152496121438\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 10. Total reward:  -1101.3634050567798\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 11. Total reward:  -1014.6355386975728\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 12. Total reward:  -501.62593967596933\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 13. Total reward:  -463.5760113785203\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 14. Total reward:  -905.5500450919919\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 15. Total reward:  -469.5494152034145\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 16. Total reward:  -902.332566625115\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 17. Total reward:  -618.6653576862949\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 18. Total reward:  -488.34037554785283\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Inference for Episode 19. Total reward:  -390.14522110572113\n",
      "Mean App Total Completion Time:  130\n",
      "Average Power Consumption per Microservice:  32.17546661503065\n",
      "Percentage Stored in Edge:  0.7432493943752249\n",
      "Percentage Stored in Cloud:  0.2567506056247752\n",
      "Average Execution Time: 1.5523131847381593 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56b3f95-dd86-4069-a78d-aa6deb95d939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -180.56\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -281.8\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -223.23\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -361.35\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -248.33\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -298.5\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -307.2\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -228.18\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -399.86\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -374.91\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -244.64\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -217.48\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -316.26\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -251.27\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -304.75\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 16 \t\t Reward: -656.93\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -301.85\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -275.34\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -291.95\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -238.58\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -300.15\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  119\n",
      "Average Power Consumption per Microservice:  39.1674500896742\n",
      "Percentage Stored in Edge:  0.2697802720508697\n",
      "Percentage Stored in Cloud:  0.7302197279491304\n",
      "Average Execution Time: 0.6594966769218444 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a088f17-d191-4a9c-a858-9d994a427758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -245.33\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -293.62\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -283.56\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -391.29\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -332.5\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -227.83\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 7 \t\t Reward: -699.63\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -279.78\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -423.74\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -247.4\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 11 \t\t Reward: -654.96\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -267.3\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 13 \t\t Reward: -862.02\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 14 \t\t Reward: -899.39\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 15 \t\t Reward: -785.97\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 16 \t\t Reward: -679.98\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -265.63\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 18 \t\t Reward: -677.68\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -311.68\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -246.63\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -453.8\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  121\n",
      "Average Power Consumption per Microservice:  38.66433131803372\n",
      "Percentage Stored in Edge:  0.27289235404413914\n",
      "Percentage Stored in Cloud:  0.7271076459558609\n",
      "Average Execution Time: 0.7559553861618042 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2170dbf-5c9f-4f5a-a57d-c150cc0ef087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -609.29\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# # Iterate over each node and its data\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# for nodes_data in microservices_in_nodes:\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m#     microservices_per_node = []\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m#     for node_set in microservices_per_node:\u001b[39;00m\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m#         print(len(node_set))\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[43mplot_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mplot_results\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_results\u001b[39m():\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# np.random.seed(0)\u001b[39;00m\n\u001b[32m     10\u001b[39m     start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     results = \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     elapsed_time = time.time() - start_time\n\u001b[32m     13\u001b[39m     num_tests = \u001b[38;5;28mlen\u001b[39m(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/test_model.py:105\u001b[39m, in \u001b[36mtest_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    103\u001b[39m     action_mask = env.get_action_mask(agent_id)\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# print(action_mask)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     action = \u001b[43mppo_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     agent_actions.append(action)\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/PPO.py:186\u001b[39m, in \u001b[36mPPO_MARL.select_action\u001b[39m\u001b[34m(self, obs_state, agent_id, action_mask)\u001b[39m\n\u001b[32m    184\u001b[39m     action_mask = torch.FloatTensor(action_mask).to(device)\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# print(\"action_mask\", action_mask)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     actions, action_logprobs, state_val, dependencies_repr, graph_repr, requests_left = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy_old\u001b[49m\u001b[43m.\u001b[49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28mself\u001b[39m.buffers[agent_id].action_masks.append(action_mask)\n\u001b[32m    189\u001b[39m \u001b[38;5;28mself\u001b[39m.buffers[agent_id].graph_states.append(graph_repr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/PPO.py:98\u001b[39m, in \u001b[36mActorCriticWorker.act\u001b[39m\u001b[34m(self, state, action_mask, batch)\u001b[39m\n\u001b[32m     94\u001b[39m graph_repr_batch = Batch.from_data_list([graph_repr])\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m###\u001b[39;00m\n\u001b[32m     96\u001b[39m \n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m### Actor Model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m req_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapplication_gnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdependencies_repr\u001b[49m\u001b[43m)\u001b[49m.squeeze() \u001b[38;5;66;03m# process current request with attention to future requests\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# print(state[\"requests_left\"])\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# print(\"req_embeddings\", req_embeddings.shape)\u001b[39;00m\n\u001b[32m    102\u001b[39m requests_left = torch.tensor([state[\u001b[33m'\u001b[39m\u001b[33mrequests_left\u001b[39m\u001b[33m'\u001b[39m]], dtype=torch.float32)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/nn_preprocessing.py:18\u001b[39m, in \u001b[36mGNNApplication.forward\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     16\u001b[39m x, edge_index = data.x, data.edge_index\n\u001b[32m     17\u001b[39m x = \u001b[38;5;28mself\u001b[39m.conv1(x, edge_index).relu()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m.relu()\n\u001b[32m     19\u001b[39m x = global_mean_pool(x, data.batch)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch_geometric/nn/conv/gcn_conv.py:263\u001b[39m, in \u001b[36mGCNConv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight)\u001b[39m\n\u001b[32m    260\u001b[39m x = \u001b[38;5;28mself\u001b[39m.lin(x)\n\u001b[32m    262\u001b[39m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    266\u001b[39m     out = out + \u001b[38;5;28mself\u001b[39m.bias\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/tmp/torch_geometric.nn.conv.gcn_conv_GCNConv_propagate_mi_9m9o8.py:183\u001b[39m, in \u001b[36mpropagate\u001b[39m\u001b[34m(self, edge_index, x, edge_weight, size)\u001b[39m\n\u001b[32m    177\u001b[39m     out = \u001b[38;5;28mself\u001b[39m.update(\n\u001b[32m    178\u001b[39m         out,\n\u001b[32m    179\u001b[39m     )\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmutable_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# Begin Message Forward Pre Hook #######################################\u001b[39;00m\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/tmp/torch_geometric.nn.conv.gcn_conv_GCNConv_propagate_mi_9m9o8.py:66\u001b[39m, in \u001b[36mcollect\u001b[39m\u001b[34m(self, edge_index, x, edge_weight, size)\u001b[39m\n\u001b[32m     63\u001b[39m edge_index_j = edge_index[j]\n\u001b[32m     65\u001b[39m ptr = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_scripting\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m edge_index.is_sorted_by_row:\n\u001b[32m     68\u001b[39m       (ptr, _), _ = edge_index.get_csr()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch/_jit_internal.py:103\u001b[39m, in \u001b[36mis_scripting\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m7\u001b[39m):\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mglobals\u001b[39m()[\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBroadcastingList\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m] = BroadcastingList1\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_scripting\u001b[39m() -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[33;03m    Function that returns True when in compilation and False otherwise. This\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[33;03m    is useful especially with the @unused decorator to leave code in your\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    120\u001b[39m \u001b[33;03m                return unsupported_linear_op(x)\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c211ec-6ba4-4327-8d4f-f05bb52fcf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -333.55\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -561.23\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -653.48\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -834.75\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -676.87\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -503.24\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -343.0\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -515.76\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -369.69\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -536.24\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -576.34\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -680.87\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -544.08\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -592.97\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -714.77\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -449.54\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -408.47\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -330.48\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -433.6\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -471.65\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -526.53\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  103\n",
      "Average Power Consumption per Microservice:  22.267458443677228\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 6.909845447540283 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6356627-313c-4035-84a9-3493d5596203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_14.91_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# # Iterate over each node and its data\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# for nodes_data in microservices_in_nodes:\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m#     microservices_per_node = []\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m#     for node_set in microservices_per_node:\u001b[39;00m\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m#         print(len(node_set))\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[43mplot_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mplot_results\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_results\u001b[39m():\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# np.random.seed(0)\u001b[39;00m\n\u001b[32m     10\u001b[39m     start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     results = \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     elapsed_time = time.time() - start_time\n\u001b[32m     13\u001b[39m     num_tests = \u001b[38;5;28mlen\u001b[39m(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/test_model.py:105\u001b[39m, in \u001b[36mtest_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    103\u001b[39m     action_mask = env.get_action_mask(agent_id)\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# print(action_mask)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     action = \u001b[43mppo_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     agent_actions.append(action)\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/PPO.py:186\u001b[39m, in \u001b[36mPPO_MARL.select_action\u001b[39m\u001b[34m(self, obs_state, agent_id, action_mask)\u001b[39m\n\u001b[32m    184\u001b[39m     action_mask = torch.FloatTensor(action_mask).to(device)\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# print(\"action_mask\", action_mask)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     actions, action_logprobs, state_val, dependencies_repr, graph_repr, requests_left = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy_old\u001b[49m\u001b[43m.\u001b[49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28mself\u001b[39m.buffers[agent_id].action_masks.append(action_mask)\n\u001b[32m    189\u001b[39m \u001b[38;5;28mself\u001b[39m.buffers[agent_id].graph_states.append(graph_repr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/PPO.py:108\u001b[39m, in \u001b[36mActorCriticWorker.act\u001b[39m\u001b[34m(self, state, action_mask, batch)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batch:\n\u001b[32m    107\u001b[39m     req_embeddings = req_embeddings.unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m node_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy_gnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_repr_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_embeddings\u001b[49m\u001b[43m)\u001b[49m.squeeze() \u001b[38;5;66;03m# process graph with attention to requests\u001b[39;00m\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# print(\"node_scores\", node_scores)\u001b[39;00m\n\u001b[32m    111\u001b[39m action_probs = torch.softmax(node_scores, dim=\u001b[32m0\u001b[39m) \u001b[38;5;66;03m# Shape: (num_of_nodes,)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/nn_preprocessing.py:91\u001b[39m, in \u001b[36mGNNAttention.forward\u001b[39m\u001b[34m(self, data, app_embedding)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, app_embedding):\n\u001b[32m     90\u001b[39m     x, edge_index, edge_weight = data.x, data.edge_index, data.edge_attr\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m.relu()\n\u001b[32m     92\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.conv2(x, edge_index, edge_weight).relu()\n\u001b[32m     94\u001b[39m     expanded_embedding_vectors = app_embedding[data.batch]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch_geometric/nn/conv/gcn_conv.py:263\u001b[39m, in \u001b[36mGCNConv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight)\u001b[39m\n\u001b[32m    260\u001b[39m x = \u001b[38;5;28mself\u001b[39m.lin(x)\n\u001b[32m    262\u001b[39m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    266\u001b[39m     out = out + \u001b[38;5;28mself\u001b[39m.bias\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/tmp/torch_geometric.nn.conv.gcn_conv_GCNConv_propagate_rvcn5qmu.py:245\u001b[39m, in \u001b[36mpropagate\u001b[39m\u001b[34m(self, edge_index, x, edge_weight, size)\u001b[39m\n\u001b[32m    236\u001b[39m             kwargs = CollectArgs(\n\u001b[32m    237\u001b[39m                 x_j=kwargs.x_j,\n\u001b[32m    238\u001b[39m                 edge_weight=kwargs.edge_weight,\n\u001b[32m   (...)\u001b[39m\u001b[32m    241\u001b[39m                 dim_size=hook_kwargs[\u001b[33m'\u001b[39m\u001b[33mdim_size\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    242\u001b[39m             )\n\u001b[32m    243\u001b[39m \u001b[38;5;66;03m# End Aggregate Forward Pre Hook #######################################\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;66;03m# Begin Aggregate Forward Hook #########################################\u001b[39;00m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_compiling():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch_geometric/nn/conv/message_passing.py:594\u001b[39m, in \u001b[36mMessagePassing.aggregate\u001b[39m\u001b[34m(self, inputs, index, ptr, dim_size)\u001b[39m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maggregate\u001b[39m(\n\u001b[32m    578\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    579\u001b[39m     inputs: Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    582\u001b[39m     dim_size: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    583\u001b[39m ) -> Tensor:\n\u001b[32m    584\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[32m    585\u001b[39m \u001b[33;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[32m    586\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    592\u001b[39m \u001b[33;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[32m    593\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maggr_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch_geometric/experimental.py:117\u001b[39m, in \u001b[36mdisable_dynamic_shapes.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    114\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: Any, **kwargs: Any) -> Any:\n\u001b[32m    116\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_experimental_mode_enabled(\u001b[33m'\u001b[39m\u001b[33mdisable_dynamic_shapes\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m required_arg \u001b[38;5;129;01min\u001b[39;00m required_args:\n\u001b[32m    120\u001b[39m         index = required_args_pos[required_arg]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch_geometric/nn/aggr/base.py:131\u001b[39m, in \u001b[36mAggregation.__call__\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m     dim_size = \u001b[38;5;28mint\u001b[39m(index.max()) + \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index.numel() > \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch_geometric/nn/aggr/basic.py:22\u001b[39m, in \u001b[36mSumAggregation.forward\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, index: Optional[Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     20\u001b[39m             ptr: Optional[Tensor] = \u001b[38;5;28;01mNone\u001b[39;00m, dim_size: Optional[\u001b[38;5;28mint\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     21\u001b[39m             dim: \u001b[38;5;28mint\u001b[39m = -\u001b[32m2\u001b[39m) -> Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mptr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch_geometric/nn/aggr/base.py:185\u001b[39m, in \u001b[36mAggregation.reduce\u001b[39m\u001b[34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAggregation requires \u001b[39m\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to be specified\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/myenv/lib/python3.12/site-packages/torch_geometric/utils/_scatter.py:75\u001b[39m, in \u001b[36mscatter\u001b[39m\u001b[34m(src, index, dim, dim_size, reduce)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reduce == \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m reduce == \u001b[33m'\u001b[39m\u001b[33madd\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     74\u001b[39m     index = broadcast(index, src, dim)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m.scatter_add_(dim, index, src)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reduce == \u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     78\u001b[39m     count = src.new_zeros(dim_size)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda33c2a-3031-4c6d-a839-459608f7a527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -398.89\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -363.8\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -414.57\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -431.94\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -489.83\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -270.14\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -462.2\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -619.63\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -574.58\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -420.72\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -699.6\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -493.29\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -285.37\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -432.7\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -547.14\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -342.11\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -363.22\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -468.06\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -315.82\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -458.28\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_12.43_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -442.59\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  100\n",
      "Average Power Consumption per Microservice:  20.160344544299683\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 5.592011964321136 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6165f51a-9a11-4a2b-aed6-2a1c981091b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -305.05\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -365.44\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -318.92\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -329.48\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -210.04\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -289.21\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -255.66\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -339.54\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -376.07\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -494.2\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -355.2\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -269.01\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -234.32\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -408.85\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -262.06\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -345.47\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -343.33\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -268.95\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -274.76\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -260.0\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -315.28\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  98\n",
      "Average Power Consumption per Microservice:  20.7715212668444\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 4.7846438646316525 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a156856-a484-4fff-9440-065e12b0d359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -326.18\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -255.07\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -298.88\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -314.34\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -383.88\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -348.81\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -251.33\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -361.69\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -340.39\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -428.28\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -221.46\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -312.6\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -362.66\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -464.36\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -267.0\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -216.43\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -297.52\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -236.76\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -277.95\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -237.84\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_9.46_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -310.17\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  89\n",
      "Average Power Consumption per Microservice:  20.821744960934502\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 5.51569310426712 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e5f17b-e8d3-4318-80fd-641ebb30f024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -500.03\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -706.96\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -540.73\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -954.89\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -586.99\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -557.69\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -471.72\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -869.71\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -823.26\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -808.71\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -569.66\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -794.56\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -1284.8\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -655.29\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -774.84\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -714.47\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -530.56\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -620.1\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -676.37\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -1028.6\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -723.5\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  141\n",
      "Average Power Consumption per Microservice:  23.612929165871396\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 8.563730597496033 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499c182b-7c00-4c0a-af27-c0f6a59df177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 1 \t\t Reward: -790.21\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -339.79\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -402.33\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -276.48\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 5 \t\t Reward: -726.3\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 6 \t\t Reward: -676.92\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -534.48\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -258.82\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Episode: 9 \t\t Reward: -835.07\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -402.6\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -387.43\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -497.48\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -401.22\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -247.04\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -510.95\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -534.18\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -309.64\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -342.38\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -344.0\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -332.53\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -457.49\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  148\n",
      "Average Power Consumption per Microservice:  42.12022938034645\n",
      "Percentage Stored in Edge:  0.26927910170500763\n",
      "Percentage Stored in Cloud:  0.7307208982949923\n",
      "Average Execution Time: 0.9255491375923157 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_greedy()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ffcd0e-34b2-437a-8f68-52f5f531bc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 0. Total reward:  -698.8260464014135\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 1. Total reward:  -422.9509595732556\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 2. Total reward:  -1003.7299729524177\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 3. Total reward:  -626.27142594694\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 4. Total reward:  -658.1738130226162\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 5. Total reward:  -613.1802101586114\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 6. Total reward:  -819.6381585301153\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 7. Total reward:  -455.7564674703572\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 8. Total reward:  -447.90055851606076\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 9. Total reward:  -594.88294323249\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 10. Total reward:  -671.9613152082558\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode finished due to mismanagement!\n",
      "Inference for Episode 11. Total reward:  -1155.4423764385\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 12. Total reward:  -830.9901082595445\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 13. Total reward:  -567.7126954597031\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 14. Total reward:  -539.886613220332\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 15. Total reward:  -673.5924249172242\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 16. Total reward:  -728.4041688337153\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 17. Total reward:  -668.5595964621273\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 18. Total reward:  -736.3204456012237\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Inference for Episode 19. Total reward:  -377.08884062733614\n",
      "Mean App Total Completion Time:  146\n",
      "Average Power Consumption per Microservice:  29.829355735736197\n",
      "Percentage Stored in Edge:  0.7864180057997114\n",
      "Percentage Stored in Cloud:  0.21358199420028856\n",
      "Average Execution Time: 1.8060557842254639 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_dqn()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9842f7fe-33be-434c-b215-8f561d4c2f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload/PPO_CNA_Environment_1_agents_large_workload_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -581.92\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -658.89\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -668.39\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -1239.78\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -572.39\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -553.62\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -663.83\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -403.04\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -708.26\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -688.71\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -771.58\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -703.47\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -548.97\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -850.27\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -531.48\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -400.95\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -614.82\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -400.24\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -725.76\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -727.72\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -650.7\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  121\n",
      "Average Power Consumption per Microservice:  22.19221474885683\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 9.144183015823364 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8860053a-ec14-45dc-9c88-1fb558dcdce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload_nongreedy\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload_nongreedy/PPO_CNA_Environment_1_agents_large_workload_nongreedy_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -231.95\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     40\u001b[39m     \u001b[38;5;66;03m# # Iterate over each node and its data\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# for nodes_data in microservices_in_nodes:\u001b[39;00m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m#     microservices_per_node = []\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     51\u001b[39m     \u001b[38;5;66;03m#     for node_set in microservices_per_node:\u001b[39;00m\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m#         print(len(node_set))\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m'\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[43mplot_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mplot_results\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_results\u001b[39m():\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# np.random.seed(0)\u001b[39;00m\n\u001b[32m     10\u001b[39m     start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     results = \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     elapsed_time = time.time() - start_time\n\u001b[32m     13\u001b[39m     num_tests = \u001b[38;5;28mlen\u001b[39m(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/test_model.py:105\u001b[39m, in \u001b[36mtest_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    103\u001b[39m     action_mask = env.get_action_mask(agent_id)\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# print(action_mask)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     action = \u001b[43mppo_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     agent_actions.append(action)\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/PPO.py:186\u001b[39m, in \u001b[36mPPO_MARL.select_action\u001b[39m\u001b[34m(self, obs_state, agent_id, action_mask)\u001b[39m\n\u001b[32m    184\u001b[39m     action_mask = torch.FloatTensor(action_mask).to(device)\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# print(\"action_mask\", action_mask)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     actions, action_logprobs, state_val, dependencies_repr, graph_repr, requests_left = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy_old\u001b[49m\u001b[43m.\u001b[49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28mself\u001b[39m.buffers[agent_id].action_masks.append(action_mask)\n\u001b[32m    189\u001b[39m \u001b[38;5;28mself\u001b[39m.buffers[agent_id].graph_states.append(graph_repr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/PPO.py:91\u001b[39m, in \u001b[36mActorCriticWorker.act\u001b[39m\u001b[34m(self, state, action_mask, batch)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m# For the current period we need the minimum available capacities\u001b[39;00m\n\u001b[32m     89\u001b[39m cpu = [\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmin\u001b[39m(node_capacity)) \u001b[38;5;28;01mfor\u001b[39;00m node_capacity \u001b[38;5;129;01min\u001b[39;00m state[\u001b[33m'\u001b[39m\u001b[33mnode_capacities\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m graph_repr = \u001b[43mpreprocessing_representations\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproduce_infr_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnode_costs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdevice_coef\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlatencies\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcurrent_allocation\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredecessors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;66;03m### Tensorize Inputs\u001b[39;00m\n\u001b[32m     93\u001b[39m dependencies_repr = Batch.from_data_list([dependencies_repr])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vs_code_workspace/preprocessing_representations.py:141\u001b[39m, in \u001b[36mproduce_infr_repr\u001b[39m\u001b[34m(node_capacities, node_costs, device_coef, latencies, current_app_allocation, predecessors)\u001b[39m\n\u001b[32m    139\u001b[39m edge_attr = []\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_nodes):\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    142\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m latencies[i, j] > \u001b[32m0\u001b[39m:\n\u001b[32m    143\u001b[39m             edge_index.append([i, j])\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b5334-ee44-431a-8ed7-f06ba7ee50d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload_nongreedy\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload_nongreedy/PPO_CNA_Environment_1_agents_large_workload_nongreedy_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -222.75\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 2 \t\t Reward: -243.9\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 3 \t\t Reward: -322.19\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 4 \t\t Reward: -325.59\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 5 \t\t Reward: -346.29\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 6 \t\t Reward: -370.97\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 7 \t\t Reward: -363.49\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 8 \t\t Reward: -377.15\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 9 \t\t Reward: -258.1\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 10 \t\t Reward: -413.21\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 11 \t\t Reward: -231.07\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 12 \t\t Reward: -278.22\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 13 \t\t Reward: -345.73\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 14 \t\t Reward: -319.01\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 15 \t\t Reward: -230.14\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 16 \t\t Reward: -432.1\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 17 \t\t Reward: -399.26\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 18 \t\t Reward: -496.4\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 19 \t\t Reward: -348.92\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "Episode: 20 \t\t Reward: -286.92\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./job_graphs_cleaned.pkl\n",
      "============================================================================================\n",
      "average test reward : -330.57\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  111\n",
      "Average Power Consumption per Microservice:  21.788181009201118\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 3.5694255232810974 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted myenv (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc25a04e-a466-4c23-89f8-530d5c6a1548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : cpu\n",
      "============================================================================================\n",
      "============================================================================================\n",
      "Training environment name : CNA_Environment_1_agents_large_workload_nongreedy\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "loading network from : PPO_preTrained/CNA_Environment_1_agents_large_workload_nongreedy/PPO_CNA_Environment_1_agents_large_workload_nongreedy_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: -652.0\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 2 \t\t Reward: -649.47\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 3 \t\t Reward: -437.15\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 4 \t\t Reward: -457.65\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 5 \t\t Reward: -590.51\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 6 \t\t Reward: -654.62\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 7 \t\t Reward: -569.28\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 8 \t\t Reward: -605.59\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 9 \t\t Reward: -526.49\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 10 \t\t Reward: -434.43\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 11 \t\t Reward: -872.99\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 12 \t\t Reward: -394.75\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 13 \t\t Reward: -731.98\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 14 \t\t Reward: -630.42\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 15 \t\t Reward: -478.69\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 16 \t\t Reward: -574.07\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 17 \t\t Reward: -681.55\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 18 \t\t Reward: -560.18\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 19 \t\t Reward: -346.13\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "Episode: 20 \t\t Reward: -844.92\n",
      "Getting traces from:  /home/panos/vs_code_workspace/./pkl_files/job_graphs_avg_20.93_tasks.pkl\n",
      "============================================================================================\n",
      "average test reward : -584.64\n",
      "============================================================================================\n",
      "Mean App Total Completion Time:  140\n",
      "Average Power Consumption per Microservice:  21.87870504476875\n",
      "Percentage Stored in Edge:  1.0\n",
      "Percentage Stored in Cloud:  0.0\n",
      "Average Execution Time: 6.192711198329926 seconds.\n"
     ]
    }
   ],
   "source": [
    "from greedy import test_greedy\n",
    "from dqn_test import test_dqn\n",
    "from test_model import test_model\n",
    "import numpy as np\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "def plot_results():\n",
    "    # np.random.seed(0)\n",
    "    start_time = time.time()\n",
    "    results = test_model()\n",
    "    elapsed_time = time.time() - start_time\n",
    "    num_tests = len(results)\n",
    "    microservices_in_nodes = []\n",
    "    total_requests = []\n",
    "    delays = []\n",
    "    consumptions = []\n",
    "    costs = []\n",
    "    stored_in_edge = []\n",
    "    stored_in_cloud = []\n",
    "    \n",
    "    for result in results:\n",
    "        total_requests.append(result.current_app_total)\n",
    "        # print(\"Number of Requests:\", total_requests[-1])\n",
    "        allocation_per_node = np.vstack((np.vstack(result.allocation_per_timeslot_domain), result.allocation_per_timeslot_shared))\n",
    "        microservices_in_nodes.append(allocation_per_node)\n",
    "        delays.append(statistics.mean(result.app_total_comp_times))\n",
    "        # consumptions.append(statistics.mean(result.operating_costs))\n",
    "        costs.append(statistics.mean(result.power_consumptions))\n",
    "        stored_in_edge.append(result.stored_in_edge/result.total_ms)\n",
    "        stored_in_cloud.append(result.stored_in_cloud/result.total_ms)\n",
    "        # print(result.total_ms)\n",
    "    print(\"Mean App Total Completion Time: \", statistics.mean(delays))\n",
    "    # print(\"Average Processing Cost per Microservice: \", statistics.mean(consumptions))\n",
    "    print(\"Average Power Consumption per Microservice: \", statistics.mean(costs))\n",
    "    print(\"Percentage Stored in Edge: \", statistics.mean(stored_in_edge))\n",
    "    print(\"Percentage Stored in Cloud: \", statistics.mean(stored_in_cloud))\n",
    "    print(\"Average Execution Time: \" + str(elapsed_time/len(results)) + \" seconds.\")\n",
    "\n",
    "    # # Iterate over each node and its data\n",
    "    # for nodes_data in microservices_in_nodes:\n",
    "    #     microservices_per_node = []\n",
    "    #     for node in nodes_data:\n",
    "    #         node_microservices = set()\n",
    "    #         for time_slot in node:\n",
    "    #             for entry in time_slot:\n",
    "    #                 # Extracting the microservice number (4th element of each tuple)\n",
    "    #                 microservice_number = entry\n",
    "    #                 node_microservices.add(microservice_number)\n",
    "    #         microservices_per_node.append(node_microservices)\n",
    "    #     for node_set in microservices_per_node:\n",
    "    #         print(len(node_set))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    plot_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
